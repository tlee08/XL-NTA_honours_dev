{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6033,"status":"ok","timestamp":1699440679682,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"2u3nhXNiUsE5"},"outputs":[],"source":["# Standard libraries\n","import os\n","from glob import glob\n","import itertools\n","import pickle\n","\n","# Basic 3rd party libraries\n","import pandas as pd\n","import numpy as np\n","\n","# Plotting libraries\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from matplotlib.ticker import StrMethodFormatter\n","\n","# scikit processing\n","from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, FunctionTransformer\n","from sklearn.model_selection import train_test_split\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# scikit models\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.multiclass import OneVsRestClassifier, OneVsOneClassifier\n","\n","# TensorFlow Keras API\n","from tensorflow.keras.utils import (\n","    plot_model as tf_plot,\n","    to_categorical,\n",")\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n","from tensorflow.keras.metrics import CategoricalAccuracy, BinaryAccuracy\n","\n","# TensorFlow Keras model and layers API\n","from tensorflow.keras.layers import (\n","    Input,\n","    Reshape,\n","    Flatten,\n","    Conv1D,\n","    Conv2D,\n","    MaxPooling1D,\n","    MaxPooling2D,\n","    Dense,\n","    Dropout,\n","    Concatenate,\n",")\n","from tensorflow.keras.models import (\n","    Sequential,\n","    Model,\n","    load_model as tf_load_model,\n",")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"pLPBDoriVHgp"},"source":["## Mounting Google Drive and setting resources path (path to captures)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TLonDjr6VfIO"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","resources_dir = '/content/drive/MyDrive/honours/captures'\n","\n","print(os.path.exists(resources_dir))"]},{"cell_type":"markdown","metadata":{"id":"rYBlHo6XVj8E"},"source":["## Setting configs\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jFgZzcJGVg1o"},"outputs":[],"source":["# Directory storing the CSI and WLAN captures\n","resources_dir = '/content/drive/MyDrive/honours/captures'\n","\n","# Directory to save plots to\n","plt_dir = '/content/drive/MyDrive/honours/figures/wlan'\n","\n","# Directory to save models to\n","models_dir = '/content/drive/MyDrive/honours/models/wlan'\n","\n","# Supress pd scientific notation\n","pd.set_option('display.float_format', '{:.6f}'.format)\n","\n","# Resolution of plots\n","plt.rcParams[\"figure.dpi\"] = 100 # 300\n","plt.rcParams[\"figure.dpi\"] = 500 # 300\n","\n","# Backend to generate plots\n","# mpl.use(\"agg\")\n","# %matplotlib ipympl\n","%matplotlib inline\n","\n","# plt figure style\n","fig_style = \"seaborn-v0_8-whitegrid\"\n","\n","# colormaps\n","cmap_qual = \"Pastel1\"\n","cmap_seq = \"viridis\"\n","cmap_cycl = \"twilight\"\n","cmap_intsy = \"Blues\"\n","\n","# Hide warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"]},{"cell_type":"markdown","metadata":{"id":"aXFCQRXG4Q5L"},"source":["## ML Preprocessing\n","\n","### Reading in total binned df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WoRQM8Pd4Ft3"},"outputs":[],"source":["X = pd.read_hdf(\n","    os.path.join(resources_dir, \"total_wlan.h5\"),\n","    key=\"wlan\",\n","    mode=\"r\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"7-HLCSUH4juV"},"source":["### Formatting total binned df as time series vector for each instance and feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usxkn_Y64ekN"},"outputs":[],"source":["# SPECIFY FEATURES TO USE\n","feature_channels = [\n","    # (with non-data, data, and all frames)\n","    # Uplink\n","    # \"frames_up_ndat\",\n","    # \"bytes_up_ndat\",\n","    # \"frames_up_dat\",\n","    # \"bytes_up_dat\",\n","    # \"frames_up_all\",\n","    # \"bytes_up_all\",\n","    # Downlink\n","    # \"frames_dn_ndat\",\n","    # \"bytes_dn_ndat\",\n","    # \"frames_dn_dat\",\n","    # \"bytes_dn_dat\",\n","    # \"frames_dn_all\",\n","    # \"bytes_dn_all\",\n","    # All\n","    # \"frames_all_ndat\",\n","    \"bytes_all_ndat\",\n","    # \"frames_all_dat\",\n","    \"bytes_all_dat\",\n","    # \"frames_all_all\",\n","    \"bytes_all_all\",\n","]\n","\n","# Making each row instance's time series vector for each column's measure\n","X_features = (\n","    X\n","    .sort_values(\"ts_bins\")\n","    .groupby([\"devices\", \"videos\", \"instances\"])\n","    .agg({i: lambda x: x.values.tolist() for i in feature_channels})\n",")\n","\n","\n","# Making a DF of the corresponding label combinations of each sample\n","# Columns: devices, locations, videos, instances\n","Y = (\n","    X_features\n","    .index\n","    .to_frame()\n","    .reset_index(drop=True)\n","    .assign(\n","        locations=lambda x: x[\"devices\"].str.split(\" \").str[1:].str.join(\" \"),\n","        devices=lambda x: x[\"devices\"].str.split(\" \").str[0],\n","    )\n","    .reindex(\n","        columns=[\"devices\", \"locations\", \"videos\", \"instances\"],\n","    )\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"RZdcXLEh8jIK"},"source":["### Setting Y Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1699345813771,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"sjDJrKSn8kgL","outputId":"3a4b8651-dddd-4aff-8241-c6297f68fa25"},"outputs":[],"source":["# SPECIFY LABELS TO USE\n","labels_to_classify = [\n","    # \"devices\",\n","    # \"locations\",\n","    \"videos\",\n","]\n","\n","# Making label combos to use\n","y = np.array(\n","    [\"|\".join(x) for x in Y[labels_to_classify].values]\n",")\n","\n","# Encode the labels\n","lb = LabelBinarizer() # one-hot encoding\n","lb.fit(y)\n","y_lb = lb.transform(y)\n","\n","y"]},{"cell_type":"markdown","metadata":{"id":"mIKxPR5R9QFp"},"source":["## Making X features matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-CIxFvq9V3M"},"outputs":[],"source":["# Making a 3D features matrix\n","# Axes format is (instance, time, feature_channel)\n","X_features_matr = (\n","    np.array(\n","        X_features.values.tolist()\n","    )\n","    .transpose(0, 2, 1)\n",")\n","\n","# MinMax scaling the 2D matrix of each feature channel\n","X_features_matr_scaled = np.zeros(X_features_matr.shape)\n","# For each feature channel (i.e., each entire (instance, time) matrix)\n","for i in np.arange(X_features_matr.shape[2]):\n","    view = X_features_matr[:, :, i]\n","    # Log transform\n","    # view = np.log1p(view)\n","    # MinMax Scale\n","    X_features_matr_scaled[:, :, i] = (view - view.min())/(view.max() - view.min())\n","# Set nan values to 0\n","X_features_matr_scaled[np.isnan(X_features_matr_scaled)] = 0"]},{"cell_type":"markdown","metadata":{"id":"B0N4x6tY_Cow"},"source":["### Visualising features to sense check"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOkwLwu86Dmt"},"outputs":[],"source":["def long_X_features(\n","    X_matr,\n","    y_vect,\n","    feature_channels,\n","    interval=1,\n","    n=4,\n","    m=100,\n","):\n","    \"\"\"\n","    Make a long dataframe with\n","    \"label\", \"instance\", \"frame\", \"feature\" variable columns and \"value\" column\n","    \"\"\"\n","    # Making df of the (label, instance) of each sample so\n","    # the original index (corresponding to each y/X sample) is maintained\n","    labs_i = pd.DataFrame({\"label\": y_vect}) # Making df of ALL labels\n","    labs_i = labs_i[labs_i[\"label\"].isin(labs_i[\"label\"].unique()[:n])] # Filtering for label subset (n)\n","    labs_i = labs_i.groupby(\"label\").head(m) # Filtering for instances subset (m)\n","    labs_i[\"instance\"] = labs_i.groupby(\"label\").cumcount() # Adding incrementing instance counts for each label\n","\n","    # Filtering dataframe for corresponding label_i subset\n","    data_matr = X_matr[labs_i.index]\n","\n","    # First making the long df with the variable columns:\n","    # instance (label, instance tuple), frame, subcarrier\n","    data = (\n","        pd.MultiIndex.from_product(\n","            [\n","                list(labs_i.itertuples(index=False, name=None)),\n","                np.arange(data_matr.shape[1])*interval,\n","                feature_channels,\n","            ],\n","            names=(\"instance\", \"ts_bin\", \"feature\"),\n","        )\n","        .to_frame(index=False)\n","    )\n","\n","    # Splitting instance column tuple to seperate label and instance columns\n","    # Adding amplitude column from data matrix\n","    data = (\n","        data\n","        .assign(\n","            label=data[\"instance\"].apply(lambda x: x[0]),\n","            instance=data[\"instance\"].apply(lambda x: x[1]),\n","            value=data_matr.reshape(-1),\n","        )\n","        .reindex(\n","            columns=[\"label\", \"instance\", \"ts_bin\", \"feature\", \"value\"],\n","        )\n","    )\n","    return data\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411,"output_embedded_package_id":"1RXijID6qj4A6fimIvhESBkYD_S8drDf-"},"executionInfo":{"elapsed":33425,"status":"ok","timestamp":1699345847765,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"fI6sYOqA6VjS","outputId":"3438c7b6-3906-4651-b6a5-80824099bbdc"},"outputs":[],"source":["# Line plots of each instance's feature's through time\n","# faceted by labels (rows) and features channels (columns)\n","\n","data = long_X_features(\n","    X_features_matr_scaled,\n","    y,\n","    feature_channels,\n","    interval=0.36,\n","    n=4,\n","    m=100,\n",")\n","\n","with plt.style.context(fig_style):\n","    g = (\n","        sns.relplot(\n","            data=data,\n","            x=\"ts_bin\",\n","            y=\"value\",\n","            hue=\"instance\",\n","            row=\"label\",\n","            col=\"feature\",\n","            palette=\"crest\",\n","            kind=\"line\",\n","            legend=False,\n","            linewidth=1,\n","            alpha=0.05,\n","            height=2,\n","            aspect=2.5,\n","            facet_kws={\"margin_titles\": True},\n","        )\n","        .set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\", size=\"xx-large\")\n","        .set_axis_labels(\"Feature\", \"Value\", size=\"xx-large\")\n","        .set(ylim=(0, 1))\n","        .tight_layout()\n","    )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":678},"executionInfo":{"elapsed":3883,"status":"ok","timestamp":1699340595754,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"ko0AdJ_7BkwD","outputId":"4cb6266d-d45a-4539-c424-5b1aa3cb9301"},"outputs":[],"source":["# Histogram of each instance's features\n","# faceted by labels (rows) and features channels (columns)\n","\n","data = long_X_features(\n","    X_features_matr_scaled,\n","    y,\n","    feature_channels,\n","    interval=0.36,\n","    n=4,\n","    m=100,\n",")\n","\n","with plt.style.context(fig_style):\n","    g = (\n","        sns.displot(\n","            data=data,\n","            x=\"value\",\n","            row=\"label\",\n","            col=\"feature\",\n","            palette=\"crest\",\n","            kind=\"hist\",\n","            stat=\"probability\",\n","            element=\"step\",\n","            legend=False,\n","            # alpha=0.5,\n","            height=2,\n","            aspect=1.5,\n","            bins=20,\n","            facet_kws={\"margin_titles\": True},\n","        )\n","        # .set(ylim=(0, 10))\n","        .set_titles(row_template=\"{row_name}\", col_template=\"{col_name}\", size=\"xx-large\")\n","        .set_xlabels(\"Value\", size=\"xx-large\")\n","        .tight_layout()\n","    )"]},{"cell_type":"markdown","metadata":{"id":"wwn5e4igHKSm"},"source":["### Making Training and Test sets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1699189732687,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"be1dRiTkHInz","outputId":"01a3122d-6494-4645-89dd-82782e458985"},"outputs":[],"source":["# Splitting the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_features_matr_scaled,\n","    y_lb,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=y_lb,\n",")\n","\n","# Flattening this data (reshaping) to feed into different ML algos\n","X_train_flat = X_train.reshape(X_train.shape[0], -1)\n","X_test_flat = X_test.reshape(X_test.shape[0], -1)\n","\n","print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"83P51u-THn-s"},"source":["## Evaluating ML Models"]},{"cell_type":"markdown","metadata":{"id":"-89-pUM1OizN"},"source":["### Helper Funcs to save and eval models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pPjEVDHHPtEQ"},"outputs":[],"source":["def get_my_model_dir(\n","    name,\n","):\n","    \"\"\"\n","    Returns the path to the model directory\n","    \"\"\"\n","    # Making directory to store model\n","    outcomes = \"_\".join([i[0] for i in labels_to_classify]) # first letter of every class group\n","    my_model_dir = os.path.join(models_dir, outcomes, name)\n","    os.makedirs(my_model_dir, exist_ok=True)\n","    return my_model_dir\n","\n","\n","def save_pkl(\n","    obj,\n","    name,\n","    suffix=\"\"\n","):\n","    \"\"\"\n","    Saves the object as a .pkl file to a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Storing object as pickle\n","    obj_fp = os.path.join(my_model_dir, f\"{name}_{suffix}.pkl\")\n","    with open(obj_fp, \"wb\") as f:\n","        pickle.dump(obj, f)\n","\n","\n","def load_pkl(\n","    name,\n","    suffix=\"\"\n","):\n","    \"\"\"\n","    Loads the .pkl file object from a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Getting filepaths\n","    obj_fp = os.path.join(my_model_dir, f\"{name}_{suffix}.pkl\")\n","    # Loading object\n","    with open(obj_fp, \"rb\") as f:\n","        obj = pickle.load(f)\n","    return obj\n","\n","\n","def save_res(\n","    y_true,\n","    y_pred,\n","    name,\n","):\n","    \"\"\"\n","    Saves the results to a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Generating and storing results as h5\n","    res_fp = os.path.join(my_model_dir, f\"{name}_res.h5\")\n","    pd.DataFrame(\n","        {\n","            \"y_true\": y_true,\n","            \"y_pred\": y_pred,\n","        }\n","    ).to_hdf(res_fp, key=\"results\", mode=\"w\")\n","\n","\n","def plot_confusion_matrix(\n","    cm,\n","    classes,\n","    title='Confusion matrix',\n","    **kwargs\n","):\n","    \"\"\"\n","    To plot heatmap of confusion matrix\n","    \"\"\"\n","    # Initialising figure and axes\n","    with plt.style.context(fig_style):\n","        fig = plt.figure(\n","            figsize=(8, 8),\n","            layout=\"constrained\"\n","        )\n","        ax = fig.subplots()\n","    # Making confusion matrix heatmap\n","    sns.heatmap(\n","        cm,\n","        annot=kwargs.get(\"annot\", False),\n","        ax=ax,\n","        cmap=kwargs.get(\"cmap\", cmap_intsy),\n","        fmt=kwargs.get(\"fmt\", \".2f\"),\n","        cbar=kwargs.get(\"cbar\", True),\n","        xticklabels=classes,\n","        yticklabels=classes,\n","    )\n","    # Set titles\n","    ax.tick_params(labelsize=\"small\")\n","    ax.set_title(title, fontsize=\"xx-large\")\n","    ax.set_xlabel(\"Predicted\", fontsize=\"large\")\n","    ax.set_ylabel(\"True\", fontsize=\"large\")\n","    # Return figure and axis\n","    return fig, ax\n","\n","def eval_model(\n","    name,\n","    lab_grouping=None,\n","):\n","    \"\"\"\n","    Evaluate the given model from the saved results h5.\n","    Can also group on the given labels (e.g., only (devices, videos))\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Reading in results\n","    res = pd.read_hdf(\n","        os.path.join(my_model_dir, f\"{name}_res.h5\"),\n","        key=\"results\",\n","        more=\"r\"\n","    )\n","    # Making label groupings for evaluation\n","    if lab_grouping:\n","        res = res.assign(\n","            y_true=lambda x: [\"|\".join(i) for i in np.array(res[\"y_true\"].str.split(\"|\").values.tolist())[:, lab_grouping]],\n","            y_pred=lambda x: [\"|\".join(i) for i in np.array(res[\"y_pred\"].str.split(\"|\").values.tolist())[:, lab_grouping]],\n","        )\n","\n","    # Getting classes\n","    classes = np.sort(res[\"y_true\"].unique())\n","\n","    # Making confusion matrix\n","    # rows = true, columns = predicted\n","    cm = confusion_matrix(\n","        y_true=res[\"y_true\"],\n","        y_pred=res[\"y_pred\"],\n","        labels=classes,\n","        normalize=None,\n","    )\n","    # Plotting confusion matrix\n","    fig, ax = plot_confusion_matrix(\n","        cm,\n","        classes,\n","        title=f\"{name} Classifier Results\",\n","        annot=True,\n","        cmap=\"Blues\",\n","        fmt=\".0f\",\n","    )\n","    fig.savefig(os.path.join(my_model_dir, f\"{name}_cm.png\"))\n","    # Classification report\n","    print(classification_report(\n","        res[\"y_true\"],\n","        res[\"y_pred\"],\n","        target_names=classes,\n","    ))\n","    (\n","        pd.DataFrame(classification_report(\n","            res[\"y_true\"],\n","            res[\"y_pred\"],\n","            target_names=classes,\n","            output_dict=True,\n","        ))\n","        .transpose()\n","        .to_csv(os.path.join(my_model_dir, f\"{name}_report.csv\"))\n","    )\n"]},{"cell_type":"markdown","metadata":{"id":"1QYW4_OZHqwp"},"source":["### KNN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1699189732687,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"fP8Len6wHl31","outputId":"afb776d7-e406-416f-f4d7-69f77a2c6a8d"},"outputs":[],"source":["# KNN WORKS VERY WELL ~ 0.64 accuracy.\n","# 1-NN seems to work best\n","\n","name = \"knn\"\n","\n","# Making KNN\n","model = KNeighborsClassifier(\n","    n_neighbors=1,\n","    weights='uniform',\n","    algorithm='auto',\n","    leaf_size=30,\n","    p=2,\n","    metric='minkowski',\n","    metric_params=None,\n","    n_jobs=None\n",")\n","\n","# Training\n","model.fit(X_train_flat, y_train)\n","\n","# Saving the model\n","save_pkl(\n","    model,\n","    name,\n","    suffix=\"model\",\n",")\n","\n","# Evaluating (from saved model)\n","model = load_pkl(\n","    name,\n","    suffix=\"model\",\n",")\n","y_pred = model.predict(X_test_flat)\n","\n","# Saving the results\n","save_res(\n","    lb.inverse_transform(y_test),\n","    lb.inverse_transform(y_pred),\n","    name,\n",")\n","# Showing results\n","eval_model(name, [0])"]},{"cell_type":"markdown","metadata":{"id":"pjgMd5I61N34"},"source":["### SVM (One vs Rest)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0gwfc2lR_MqB"},"outputs":[],"source":["# # SVM OVR is similar performance to KNN but much slower to train\n","\n","# name = \"svc_ovr\"\n","\n","# # Making RBF SVC\n","# model = SVC(\n","#     C=2.0, # Regularisation parameter. Reg strength is inversely proportional to C\n","#     kernel='rbf', # {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable\n","#     # degree=3, # Degree for poly kernels\n","#     gamma='scale', # {‘scale’, ‘auto’} or float\n","#     coef0=0.0, # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n","#     shrinking=True, # Whether to use the shrinking heuristic\n","#     probability=False, # Allows predict_proba but slows down process\n","#     tol=0.001, # Tolerance for stopping criterion.\n","#     cache_size=200, # Specify the size of the kernel cache in MB\n","#     class_weight=None, # Set the parameter C of class i to class_weight[i]*C. Keep as none for equal weights across classes\n","#     verbose=False, # Enable verbose output\n","#     max_iter=-1, # Hard limit on iterations within solver, or -1 for no limit\n","#     decision_function_shape='ovo', # {‘ovo’, ‘ovr’}\n","#     break_ties=False,\n","#     random_state=None\n","# )\n","# model = OneVsRestClassifier(\n","#     model,\n","#     n_jobs=4,\n","# )\n","\n","# # Training\n","# model.fit(X_train_flat, y_train)\n","\n","# # Saving the model\n","# save_pkl(\n","#     model,\n","#     name,\n","#     suffix=\"model\",\n","# )\n","\n","# # Evaluating (from saved model)\n","# model = load_pkl(\n","#     name,\n","#     suffix=\"model\",\n","# )\n","# y_pred = model.predict(X_test_flat)\n","\n","# # Saving the results\n","# save_res(\n","#     lb.inverse_transform(y_test),\n","#     lb.inverse_transform(y_pred),\n","#     name,\n","# )\n","# # Showing results\n","# eval_model(name, [0])"]},{"cell_type":"markdown","metadata":{"id":"K7pEuLU__KwY"},"source":["### SVM (One vs One)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":37993,"status":"ok","timestamp":1699189770673,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"frQTw50R6lZs","outputId":"151436f6-784d-4145-92d5-497a01097c68"},"outputs":[],"source":["# SVM OVO is ~ 0.78% accuracy.\n","\n","name = \"svc_ovo\"\n","\n","# Making RBF SVC\n","model = SVC(\n","    C=2.0, # Regularisation parameter. Reg strength is inversely proportional to C\n","    kernel='rbf', # {‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’} or callable\n","    # degree=3, # Degree for poly kernels\n","    gamma='scale', # {‘scale’, ‘auto’} or float\n","    coef0=0.0, # Independent term in kernel function. It is only significant in ‘poly’ and ‘sigmoid’.\n","    shrinking=True, # Whether to use the shrinking heuristic\n","    probability=False, # Allows predict_proba but slows down process\n","    tol=0.001, # Tolerance for stopping criterion.\n","    cache_size=200, # Specify the size of the kernel cache in MB\n","    class_weight=None, # Set the parameter C of class i to class_weight[i]*C. Keep as none for equal weights across classes\n","    verbose=False, # Enable verbose output\n","    max_iter=-1, # Hard limit on iterations within solver, or -1 for no limit\n","    decision_function_shape='ovo', # {‘ovo’, ‘ovr’}\n","    break_ties=False,\n","    random_state=None\n",")\n","model = OneVsOneClassifier(\n","    model,\n","    n_jobs=4,\n",")\n","\n","# Converting binarised labels (vectors) to encoded (single val)\n","le = LabelEncoder()\n","y_le_train = le.fit_transform(lb.inverse_transform(y_train))\n","y_le_test = le.transform(lb.inverse_transform(y_test))\n","\n","# Training\n","model.fit(X_train_flat, y_le_train)\n","\n","# Saving the model\n","save_pkl(\n","    model,\n","    name,\n","    suffix=\"model\",\n",")\n","\n","# Evaluating (from saved model)\n","model = load_pkl(\n","    name,\n","    suffix=\"model\",\n",")\n","y_pred = model.predict(X_test_flat)\n","\n","# Saving the results\n","save_res(\n","    le.inverse_transform(y_le_test),\n","    le.inverse_transform(y_pred),\n","    name,\n",")\n","# Showing results\n","eval_model(name, [0])"]},{"cell_type":"markdown","metadata":{"id":"exBCxKkJW3SO"},"source":["## Deep Learning Models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Shz-wKnW67e"},"outputs":[],"source":["def save_model_tf(\n","    model,\n","    name,\n","\n","):\n","    \"\"\"\n","    Saves the TensorFlow Keras model to a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Storing model as .keras\n","    model_fp = os.path.join(my_model_dir, f\"{name}.keras\")\n","    model.save(model_fp)\n","\n","def save_weights_tf(\n","    model,\n","    name,\n","):\n","    \"\"\"\n","    Saves the TensorFlow Keras model weights to a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Storing model as .keras\n","    weights_fp = os.path.join(my_model_dir, f\"{name}\")\n","    model.save_weights(weights_fp)\n","\n","\n","def save_architecture_tf(\n","    model,\n","    name\n","):\n","    \"\"\"\n","    Saves the TensorFlow Keras model architecture to a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Saving architecture diagram\n","    archt_fp = os.path.join(my_model_dir, f\"{name}.png\")\n","    tf_plot(\n","        model,\n","        to_file=archt_fp,\n","        show_shapes=True,\n","        show_dtype=True,\n","        show_layer_names=False,\n","        rankdir=\"TB\",\n","        expand_nested=True,\n","        show_layer_activations=True,\n","        show_trainable=False,\n","    )\n","\n","\n","def load_model_tf(\n","    name,\n","    load_weights=True,\n","):\n","    \"\"\"\n","    Loads the TensorFlow Keras model from a folder (given by name)\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Getting filepaths\n","    model_fp = os.path.join(my_model_dir, f\"{name}.keras\")\n","    weights_fp = os.path.join(my_model_dir, f\"{name}\")\n","    # Loading model\n","    model = tf_load_model(model_fp)\n","    # Loading best weights\n","    if load_weights:\n","        try:\n","            model.load_weights(weights_fp)\n","        except:\n","            pass\n","    return model\n","\n","\n","def make_checkpoint_cb(name):\n","    \"\"\"\n","    Make the ModelCheckpoint callback to save the model during training.\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    os.makedirs(my_model_dir, exist_ok=True)\n","    # Making model checkpoint callback\n","    checkpoint_fp = os.path.join(my_model_dir, f\"{name}\")\n","    cp_callback = ModelCheckpoint(\n","        filepath=checkpoint_fp,\n","        verbose=1,\n","        save_weights_only=True,\n","        save_freq=\"epoch\",\n","        monitor=\"val_categorical_accuracy\",\n","        mode=\"max\",\n","        save_best_only=True,\n","    )\n","    # Returning callback\n","    return cp_callback\n","\n","\n","def train_tf(\n","    name,\n","    hparams,\n","    X_train,\n","    y_train,\n","):\n","    \"\"\"\n","    Trains a TensorFlow Keras model.\n","    Steps are:\n","        - Configure the model for training\n","        - Training the model\n","        - Saving the model\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Loading model\n","    model = load_model_tf(name, load_weights=False)\n","\n","    # Remove old weights\n","    for i in [\"checkpoint\", \".index\", \".data\"]:\n","        fps = glob(os.path.join(my_model_dir, f\"*{i}*\"))\n","        [os.remove(fp) for fp in fps]\n","\n","    # Configure the model for training\n","    model.compile(\n","        optimizer=Adam(\n","            learning_rate=hparams[\"learning_rate\"],\n","        ),\n","        loss=hparams[\"loss\"],\n","        metrics=[\n","            CategoricalAccuracy(),\n","            BinaryAccuracy(),\n","        ],\n","        loss_weights=None,\n","        weighted_metrics=None,\n","        run_eagerly=None,\n","        steps_per_execution=None,\n","        jit_compile=None,\n","        # pss_evaluation_shards=0,\n","    )\n","\n","    # Training the model\n","    history = model.fit(\n","        X_train,\n","        y_train,\n","        epochs=hparams[\"epochs\"],\n","        batch_size=hparams[\"batch_size\"],\n","        validation_split=hparams[\"validation_split\"],\n","        verbose=hparams[\"verbose\"],\n","        callbacks=[\n","            make_checkpoint_cb(name),\n","            EarlyStopping(\n","                monitor=hparams[\"stopping_monitor\"],\n","                min_delta=0,\n","                patience=10,\n","                verbose=1,\n","                mode=\"auto\",\n","                baseline=0,\n","                restore_best_weights=False,\n","                start_from_epoch=0,\n","            )\n","        ],\n","        use_multiprocessing=True,\n","    )\n","\n","    # Saving the model\n","    save_model_tf(model, name)\n","    # Saving model history\n","    save_pkl(\n","        history,\n","        name,\n","        suffix=\"history\",\n","    )\n","    # Saving model hyperparams\n","    save_pkl(\n","        hparams,\n","        name,\n","        suffix=\"hparams\",\n","    )\n","\n","def eval_tf(\n","    name,\n","    X_test,\n","    y_test,\n","    lab_grouping=None,\n","    metrics=[\"loss\", \"categorical_accuracy\"]\n","):\n","    \"\"\"\n","    Evaluates a TensorFlow Keras model.\n","    Steps are:\n","        - Evaluating (from saved model)\n","        - Saving the results\n","        - Showing results\n","    \"\"\"\n","    my_model_dir = get_my_model_dir(name)\n","    # Loading model\n","    model = load_model_tf(name)\n","\n","    # Predicting the test labels\n","    y_pred = model.predict(X_test)\n","\n","    # Saving the results\n","    save_res(\n","        lb.inverse_transform(y_test),\n","        lb.inverse_transform(y_pred),\n","        name,\n","    )\n","    # Showing results\n","    eval_model(name, lab_grouping)\n","\n","    # Showing training convergence\n","    # Loading history\n","    history = load_pkl(name, suffix=\"history\")\n","    h = pd.DataFrame(history.history)\n","    # Plotting training accuracy and loss convergence\n","    with plt.style.context(fig_style):\n","        fig, axes = plt.subplots(ncols=2)\n","    for i_k, i_v in enumerate(metrics):\n","        sns.lineplot(\n","            data=(\n","                h[[f\"{j}{i_v}\" for j in [\"\", \"val_\"]]]\n","                .melt(\n","                    var_name=\"variable\",\n","                    value_name=\"value\",\n","                    ignore_index=False)\n","                .reset_index(\n","                    names=\"epoch\",\n","                )\n","            ),\n","            x=\"epoch\",\n","            y=\"value\",\n","            hue=\"variable\",\n","            palette=cmap_qual,\n","            ax=axes[i_k],\n","        )\n","        axes[i_k].set_title(f\"{i_v}\")\n","    fig.savefig(os.path.join(my_model_dir, f\"{name}_history.png\"))\n"]},{"cell_type":"markdown","metadata":{"id":"RJ8MhGZW7DwF"},"source":["### MLP Model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":18677,"status":"ok","timestamp":1699189789292,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"z51KXhFZ7B5F","outputId":"ec591fa6-e450-4dc1-d90f-71b3ed4130c0"},"outputs":[],"source":["name = \"MLP_V1\"\n","\n","# Hyper-parameters\n","hparams = {\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"validation_split\": 0.2,\n","    \"verbose\": True,\n","    \"learning_rate\": 0.001,\n","    \"loss\": CategoricalCrossentropy(), # FOR CATEGORICAL CLASSIFICATION\n","    \"stopping_monitor\":\"val_categorical_accuracy\", # FOR CATEGORICAL CLASSIFICATION\n","    # \"loss\": BinaryCrossentropy(), # FOR BINARY CLASSIFICATION\n","    # \"stopping_monitor\":\"val_binary_accuracy\", # FOR BINARY CLASSIFICATION\n","}\n","\n","# Making MLP model Architecture\n","in1 = Input(shape=X_train.shape[1:])\n","m1 = Sequential(\n","    [\n","        Flatten(\n","            name=\"flatten\",\n","        ),\n","        Dense(\n","            300, activation=\"relu\", name=\"dense_1\",\n","        ),\n","        Dense(\n","            100, activation=\"relu\", name=\"dense_2\",\n","        ),\n","        Dropout(\n","            0.5, name=\"dropout_1\"\n","        ),\n","        Dense( # FOR CATEGORICAL CLASSIFICATION\n","            len(lb.classes_), activation=\"softmax\", name=\"output\"\n","        ),\n","        # Dense( # FOR BINARY CLASSIFICATION\n","        #     1, activation=\"sigmoid\", name=\"output\"\n","        # ),\n","    ],\n","    name=\"MLP_V1\"\n",")(in1)\n","\n","model = Model(\n","    inputs=[in1],\n","    outputs=[m1],\n","    name=name,\n",")\n","\n","# Show model architecture\n","model.summary()\n","\n","# Saving model\n","save_model_tf(model, name)\n","# Save architecture\n","save_architecture_tf(model, name)\n","\n","# Training model\n","train_tf(name, hparams, X_train, y_train)\n","\n","# Evaluating model\n","eval_tf(\n","    name,\n","    X_test,\n","    y_test,\n","    lab_grouping=[0],\n","    # metrics=[\"loss\", \"binary_accuracy\"],\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"ngPl_I82I7Ub"},"source":["### CNN Model V1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":25307,"status":"ok","timestamp":1699189814571,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"CUVqLQ8pI9VP","outputId":"841cef5b-dec9-44ba-a5ad-8961772d724f"},"outputs":[],"source":["# Simpler CNN. Accuracy ~ 0.88\n","\n","name = \"CNN_V1\"\n","\n","# Hyper-parameters\n","hparams = {\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"validation_split\": 0.2,\n","    \"verbose\": True,\n","    \"learning_rate\": 0.001,\n","    \"loss\": CategoricalCrossentropy(), # FOR CATEGORICAL CLASSIFICATION\n","    \"stopping_monitor\":\"val_categorical_accuracy\", # FOR CATEGORICAL CLASSIFICATION\n","    # \"loss\": BinaryCrossentropy(), # FOR BINARY CLASSIFICATION\n","    # \"stopping_monitor\":\"val_binary_accuracy\", # FOR BINARY CLASSIFICATION\n","}\n","\n","# Making CNN model Architecture\n","in1 = Input(shape=X_train.shape[1:])\n","m1 = Sequential(\n","    [\n","        Conv1D(\n","            8, 5, padding=\"valid\", activation=\"relu\", name=\"conv_1\",\n","        ),\n","        MaxPooling1D(\n","            2, name=\"maxpool_1\",\n","        ),\n","        Conv1D(\n","            16, (3,), padding=\"valid\", activation=\"relu\", name=\"conv_2\",\n","        ),\n","        Flatten(\n","            name=\"flatten\",\n","        ),\n","        Dense(\n","            64, activation=\"relu\", name=\"dense_1\",\n","        ),\n","        Dropout(\n","            0.5, name=\"dropout_1\"\n","        ),\n","        Dense( # FOR CATEGORICAL CLASSIFICATION\n","            len(lb.classes_), activation=\"softmax\", name=\"output\"\n","        ),\n","        # Dense( # FOR BINARY CLASSIFICATION\n","        #     1, activation=\"sigmoid\", name=\"output\"\n","        # ),\n","    ],\n","    name=\"CNN_V1\",\n",")(in1)\n","\n","model = Model(\n","    inputs=[in1],\n","    outputs=[m1],\n","    name=name,\n",")\n","\n","# Show model architecture\n","model.summary()\n","\n","# Saving model\n","save_model_tf(model, name)\n","# Save architecture\n","save_architecture_tf(model, name)\n","\n","# Training model\n","train_tf(name, hparams, X_train, y_train)\n","\n","# Evaluating model\n","eval_tf(\n","    name,\n","    X_test,\n","    y_test,\n","    lab_grouping=[0],\n","    # metrics=[\"loss\", \"binary_accuracy\"],\n",")\n"]},{"cell_type":"markdown","metadata":{"id":"6j5M9X-IFnsQ"},"source":["### CNN Model V2\n","From Deep Content paper"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":24416,"status":"ok","timestamp":1699189838980,"user":{"displayName":"Timothy Lee","userId":"05528470227050319779"},"user_tz":-660},"id":"8Xg5J4a5g6ui","outputId":"21d5d575-4961-47cc-c0cf-0e23f3a45d73"},"outputs":[],"source":["# Deep Content CNN.\n","\n","name = \"CNN_V2\"\n","\n","# Hyper-parameters\n","hparams = {\n","    \"epochs\": 100,\n","    \"batch_size\": 64,\n","    \"validation_split\": 0.2,\n","    \"verbose\": True,\n","    \"learning_rate\": 0.001,\n","    \"loss\": CategoricalCrossentropy(), # FOR CATEGORICAL CLASSIFICATION\n","    \"stopping_monitor\":\"val_categorical_accuracy\", # FOR CATEGORICAL CLASSIFICATION\n","    # \"loss\": BinaryCrossentropy(), # FOR BINARY CLASSIFICATION\n","    # \"stopping_monitor\":\"val_binary_accuracy\", # FOR BINARY CLASSIFICATION\n","}\n","\n","# Making CNN model Architecture\n","in1 = Input(shape=X_train.shape[1:])\n","m1 = Sequential(\n","    [\n","        Conv1D(\n","            8, 5, padding=\"valid\", activation=\"relu\", name=\"conv_1\",\n","        ),\n","        MaxPooling1D(\n","            2, name=\"maxpool_1\",\n","        ),\n","        Conv1D(\n","            16, (3,), padding=\"valid\", activation=\"relu\", name=\"conv_2\",\n","        ),\n","        MaxPooling1D(\n","            2, name=\"maxpool_2\",\n","        ),\n","        Dropout(\n","            0.5, name=\"dropout_1\"\n","        ),\n","        Conv1D(\n","            16, (3,), padding=\"valid\", activation=\"relu\", name=\"conv_3\",\n","        ),\n","        Flatten(\n","            name=\"flatten\",\n","        ),\n","        Dense(\n","            64, activation=\"relu\", name=\"dense_1\",\n","        ),\n","        Dropout(\n","            0.5, name=\"dropout_2\"\n","        ),\n","        Dense( # FOR CATEGORICAL CLASSIFICATION\n","            len(lb.classes_), activation=\"softmax\", name=\"output\"\n","        ),\n","        # Dense( # FOR BINARY CLASSIFICATION\n","        #     1, activation=\"sigmoid\", name=\"output\"\n","        # ),\n","    ],\n","    name=\"CNN_V2\"\n",")(in1)\n","\n","model = Model(\n","    inputs=[in1],\n","    outputs=[m1],\n","    name=name,\n",")\n","\n","# Show model architecture\n","model.summary()\n","\n","# Saving model\n","save_model_tf(model, name)\n","# Save architecture\n","save_architecture_tf(model, name)\n","\n","# Training model\n","train_tf(name, hparams, X_train, y_train)\n","\n","# Evaluating model\n","eval_tf(\n","    name,\n","    X_test,\n","    y_test,\n","    lab_grouping=[0],\n","    # metrics=[\"loss\", \"binary_accuracy\"],\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcKmZPX9Unfp"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNUHAnK2Uh1b4v7tJYzutZr","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
