{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from glob import glob\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory storing the CSI and WLAN captures\n",
    "resources_dir = \"/Volumes/tim_details/tim_honours/CAPTURES\"\n",
    "\n",
    "# Directory to save plots to\n",
    "plt_dir = \"/Users/timothylee/Desktop/Uni/Yr5/Honours/honours_thesis/figures/plt_figs/\"\n",
    "\n",
    "# Supress pd scientific notation\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "# Resolution of plots\n",
    "plt.rcParams[\"figure.dpi\"] = 100 # 300\n",
    "# plt.rcParams[\"figure.dpi\"] = 500 # 300\n",
    "\n",
    "# Backend to generate plots\n",
    "# mpl.use(\"agg\")\n",
    "# %matplotlib ipympl\n",
    "%matplotlib inline\n",
    "\n",
    "# plt figure style\n",
    "fig_style = \"seaborn-v0_8-whitegrid\"\n",
    "\n",
    "# colormaps\n",
    "cmap_qual = \"pastel\"\n",
    "cmap_seq = \"viridis\"\n",
    "cmap_cycl = \"twilight\"\n",
    "\n",
    "# Hide warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Dataset Functions\n",
    "\n",
    "* Binning and Aggregating\n",
    "* Combining Different Filters\n",
    "* Handling CSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_bin_df(df, interval, end_time, agg_dict):\n",
    "    \"\"\"\n",
    "    Bins data into the given intervals.\n",
    "    Also includes all missing intervals and sorts the index.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # Generating time-bins\n",
    "    time_series = df[\"frame.time_relative\"]\n",
    "    # If the df is empty (i.e. empty capture)\n",
    "    if time_series.shape[0] == 0:\n",
    "        return pd.DataFrame(columns=list(agg_dict.keys()))\n",
    "    # Making list of bins from 0 to at least the end_time\n",
    "    bins = np.arange(\n",
    "        0,\n",
    "        np.max([np.ceil(time_series.max()) + interval, end_time]),\n",
    "        interval,\n",
    "    )\n",
    "    # Adding binned category column to data\n",
    "    df[\"ts_bins\"] = pd.cut(\n",
    "        time_series,\n",
    "        bins=bins,\n",
    "        include_lowest=True,\n",
    "        labels=bins[:-1],\n",
    "    )\n",
    "\n",
    "    # Grouping and aggregating data on time bins\n",
    "    df_binned = df.groupby(\"ts_bins\").agg(agg_dict)\n",
    "    # Ensuring that there are all timebins (even if some rows are empty)\n",
    "    df_binned = (\n",
    "        df_binned\n",
    "        .reset_index()\n",
    "        .merge(pd.Series(bins, name=\"ts_bins\"), on=\"ts_bins\", how=\"right\")\n",
    "        .set_index(\"ts_bins\")\n",
    "        .sort_index()\n",
    "    )\n",
    "    return df_binned\n",
    "\n",
    "\n",
    "def bin_filt_df(df, interval, end_time, agg_dict):\n",
    "    \"\"\"\n",
    "    Bins data into intervals, with different characteristics\n",
    "    filtered by direction and frame type.\n",
    "    Uses ts_bin_df to bin the data.\n",
    "    \"\"\"\n",
    "    # Initialising binned df\n",
    "    df_binned = pd.DataFrame()\n",
    "    # Making bins for each filter (direction, data/non-data frame):\n",
    "    # Direction\n",
    "    for d_k, d_v in {\"up\": (True,), \"dn\": (False,), \"all\": None}.items():\n",
    "        # Frame Type: https://en.wikipedia.org/wiki/802.11_Frame_Types\n",
    "        for fc_k, fc_v in {\"ndat\": (0, 1), \"dat\": (2,), \"all\": None}.items():\n",
    "            # Filtering df\n",
    "            df_f = df\n",
    "            if d_v:\n",
    "                df_f = df_f[df_f[\"is_upstream\"].isin(d_v)]\n",
    "            if fc_v:\n",
    "                df_f = df_f[df_f[\"wlan.fc.type\"].isin(fc_v)]\n",
    "            # Making the binned df\n",
    "            df_f_binned = ts_bin_df(df_f, interval, end_time, agg_dict)\n",
    "            # Adding this filtered df to the total \n",
    "            df_binned = df_binned.merge(\n",
    "                right=df_f_binned.add_suffix(f\"_{d_k}_{fc_k}\"),\n",
    "                how=\"outer\",\n",
    "                left_index=True,\n",
    "                right_index=True,\n",
    "            )\n",
    "    return df_binned\n",
    "\n",
    "\n",
    "def df_to_csi_matrix(df):\n",
    "    \"\"\"\n",
    "    Converts the df format of CSI (i, r) values to 2D matrix format of complex values.\n",
    "    \"\"\"\n",
    "    # Getting the shape of CSI matrix (# subcarriers, and # frames)\n",
    "    nsubs = int(np.sum([\"csi_\" in i for i in df.columns]) / 2)\n",
    "    nframes = df.shape[0]\n",
    "    # Initialising CSI matrix\n",
    "    csi = np.zeros((nframes, nsubs), dtype=np.complex64)\n",
    "    # Filling CSI matrix values\n",
    "    for i in np.arange(nsubs):\n",
    "        csi[:, i] = (df[f\"csi_{i}_r\"] + 1j * df[f\"csi_{i}_i\"]).astype(np.complex64)\n",
    "    # Returning complex CSI matrix\n",
    "    return csi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Labels to Combine On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devices = {\n",
    "    \"client_pc_50\": \"PC 50 cm\",\n",
    "    \"client_pc_200\": \"PC 200 cm\",\n",
    "    \"client_pc_200_wall\": \"PC 200 cm (wall)\",\n",
    "    \"client_pi_50\":  \"RPi4 50 cm\",\n",
    "    \"client_pi_200\": \"RPi4 200 cm\",\n",
    "    \"client_pi_200_wall\": \"RPi4 200 cm (wall)\",\n",
    "}\n",
    "videos = {\n",
    "    \"v=3InbMow9IYo\": \"Vid 1\",\n",
    "    \"v=A3gUpodXMv0\": \"Vid 2\",\n",
    "    \"v=NSW5u1RTxEA\": \"Vid 3\",\n",
    "    \"v=gxxqdrrpgZc\": \"Vid 4\",\n",
    "    \"v=mkWKZWMokdI\": \"Vid 5\",\n",
    "    \"v=t634q_Voeto\": \"Vid 6\",\n",
    "    \"v=t6jlhqNxRYk\": \"Vid 7\",\n",
    "    \"v=w_oGIbFjiCo\": \"Vid 8\",\n",
    "    \"v=yve6qo6eowU\": \"Vid 9\",\n",
    "}\n",
    "labels = pd.DataFrame(columns=[\"devices\", \"videos\"])\n",
    "for i in itertools.product(devices, videos):\n",
    "    labels.loc[len(labels)] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining WLAN binned data into a single H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and aggregating data on time bins\n",
    "agg_dict = {\n",
    "    \"frames\": \"count\", # #frames\n",
    "    \"bytes\": \"sum\", # #bytes\n",
    "}\n",
    "\n",
    "# Making combined binned DF of all labels and instances\n",
    "interval = 0.36 # Binning interval in seconds\n",
    "end_time = 180\n",
    "X = pd.DataFrame()\n",
    "# For each label combination\n",
    "for i in labels.index:\n",
    "    # Getting the particular label details\n",
    "    row = labels.loc[i]\n",
    "    print(row.values)\n",
    "    # For reach capture in the label combination folder\n",
    "    for fp in glob(os.path.join(resources_dir, row[\"devices\"], row[\"videos\"], \"wlan_h5\", \"*.h5\")):\n",
    "        # Reading the wlan h5 file\n",
    "        df = pd.read_hdf(\n",
    "            fp,\n",
    "            key=\"wlan\",\n",
    "            mode=\"r\",\n",
    "        )\n",
    "\n",
    "        # Not including captures with less than 150 seconds (i.e. invalid capture)\n",
    "        if df[\"frame.time_relative\"].max() < 150:\n",
    "            continue\n",
    "\n",
    "        # Adding a column to track the frame count\n",
    "        df[\"frames\"] = np.arange(df.shape[0])\n",
    "        # renaming columns\n",
    "        df = df.rename(columns={\"frame.len\": \"bytes\"})\n",
    "\n",
    "        # Binning df with different filters\n",
    "        df_binned = bin_filt_df(df, interval, 180, agg_dict)\n",
    "\n",
    "        # Taking the first 500 bins (i.e. 180 seconds)\n",
    "        df_binned = df_binned.iloc[:500]\n",
    "        # Imputing missing values\n",
    "        df_binned = df_binned.fillna(0) # all (set to 0)\n",
    "        # Setting the ts_bins index as a column\n",
    "        df_binned[\"ts_bins\"] = df_binned.index\n",
    "\n",
    "        # Adding label combo to group instances\n",
    "        df_binned[\"devices\"] = devices[row['devices']]\n",
    "        df_binned[\"videos\"] = videos[row['videos']]\n",
    "        df_binned[\"instances\"] = os.path.split(fp)[1]\n",
    "\n",
    "        # Concatenating the instance's binned df to the overall binned df (df_all)\n",
    "        X = pd.concat([X, df_binned], axis=0, ignore_index=True)\n",
    "\n",
    "# Saving to h5 file\n",
    "# X.to_hdf(\n",
    "#     os.path.join(resources_dir, \"total_wlan.h5\"),\n",
    "#     key=\"wlan\",\n",
    "#     mode=\"w\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining CSI binned data into a single H5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Grouping and aggregating data on time bins\n",
    "agg_dict = {\n",
    "    \"frames\": \"count\" # #frames\n",
    "}\n",
    "for i in np.arange(64):\n",
    "    agg_dict[f\"csi_{i}_a\"] = \"mean\"\n",
    "    agg_dict[f\"csi_{i}_p\"] = \"mean\"\n",
    "\n",
    "# Making combined binned DF of all labels and instances\n",
    "interval = 0.36 # Binning interval in seconds\n",
    "end_time = 180\n",
    "X = pd.DataFrame()\n",
    "# For each label combination\n",
    "for i in labels.index:\n",
    "    # Getting the particular label details\n",
    "    row = labels.loc[i]\n",
    "    print(row.values)\n",
    "    # For reach capture in the label combination folder\n",
    "    for fp in glob(os.path.join(resources_dir, row[\"devices\"], row[\"videos\"], \"csi_h5\", \"*.h5\")):\n",
    "        # Reading the wlan h5 file\n",
    "        df = pd.read_hdf(\n",
    "            fp,\n",
    "            key=\"csi\",\n",
    "            mode=\"r\",\n",
    "        )\n",
    "\n",
    "        # Not including captures with less than 150 seconds (i.e. invalid capture)\n",
    "        if df[\"frame.time_relative\"].max() < 150:\n",
    "            continue\n",
    "\n",
    "        # Converting df CSI columns from \"r\" and \"i\" columns to combined complex\n",
    "        # Getting CSI matrix\n",
    "        csi = df_to_csi_matrix(df)\n",
    "        # Dropping old CSI columns from DF\n",
    "        df = df.loc[:,[\"csi_\" not in i for i in df.columns]]\n",
    "        # Adding complex CSI columns to DF\n",
    "        for i in np.arange(csi.shape[1]):\n",
    "            # df[f\"csi_{i}\"] = csi[:, i]\n",
    "            df[f\"csi_{i}_a\"] = np.abs(csi[:, i])\n",
    "            df[f\"csi_{i}_p\"] = np.angle(csi[:, i])\n",
    "\n",
    "        # Adding a column to track the frame count\n",
    "        df[\"frames\"] = np.arange(df.shape[0])\n",
    "\n",
    "        # Binning df with different filters\n",
    "        df_binned = ts_bin_df(df, interval, end_time, agg_dict)\n",
    "\n",
    "        # Taking the first 500 bins (i.e. 180 seconds)\n",
    "        df_binned = df_binned.iloc[:500]\n",
    "        # Imputing missing values\n",
    "        df_binned[\"frames\"] = df_binned[\"frames\"].fillna(0) # Frames (set to 0)\n",
    "        df_binned = df_binned.interpolate(method=\"linear\", axis=0) # CSI (interpolation)\n",
    "        # Setting the ts_bins index as a column\n",
    "        df_binned[\"ts_bins\"] = df_binned.index\n",
    "\n",
    "        # Adding label combo to group instances\n",
    "        df_binned[\"devices\"] = devices[row['devices']]\n",
    "        df_binned[\"videos\"] = videos[row['videos']]\n",
    "        df_binned[\"instances\"] = os.path.split(fp)[1]\n",
    "\n",
    "        # Concatenating the instance's binned df to the overall binned df (df_all)\n",
    "        X = pd.concat([X, df_binned], axis=0, ignore_index=True)\n",
    "\n",
    "# Saving to h5 file\n",
    "# X.to_hdf(\n",
    "#     os.path.join(resources_dir, \"total_csi.h5\"),\n",
    "#     key=\"csi\",\n",
    "#     mode=\"w\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking correct timebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_hdf(\n",
    "    os.path.join(resources_dir, \"total_wlan.h5\"),\n",
    "    key=\"wlan\",\n",
    "    mode=\"r\"\n",
    ")\n",
    "\n",
    "display(\n",
    "    pd\n",
    "    .MultiIndex\n",
    "    .from_frame(X[[\"devices\", \"videos\", \"instances\"]])\n",
    "    .unique()\n",
    "    .shape\n",
    ")\n",
    "\n",
    "display(\n",
    "    X\n",
    "    .groupby([\"devices\", \"videos\", \"instances\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"ts_bins\": [\"count\", \"max\"],\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "honours_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
